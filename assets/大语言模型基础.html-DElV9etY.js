import{ah as r,ai as a,ar as e,ak as i,al as l,am as o}from"./app-BkIbqy-o.js";const s="/assets/image-20250602105341874-dUdCwCdO.png",d="/assets/image-20250602210703011-Cf-nj8t9.png",m={};function p(c,t){const n=l("Mermaid");return o(),a("div",null,[t[0]||(t[0]=e('<h1 id="大模型技术基础" tabindex="-1"><a class="header-anchor" href="#大模型技术基础"><span>大模型技术基础</span></a></h1><h2 id="大语言模型概念" tabindex="-1"><a class="header-anchor" href="#大语言模型概念"><span>大语言模型概念</span></a></h2><p>定义： 通常指具有超大规模参数的预训练模型</p><p>架构：主要为transformer解码器架构</p><p>训练：</p><ul><li>预训练（base model) 建立模型的<strong>基础能力</strong><ul><li>数据： 海量文本数据</li><li>优化：预测下一个词</li></ul></li><li>后训练 (instruct model) 增强模型的<strong>任务能力</strong><ul><li>数据： 大量指令数据</li><li>优化： SFT、RL等方法</li></ul></li><li>下游应用 <ul><li>测速（推理）</li></ul></li></ul>',6)),i(n,{id:"mermaid-63",code:"eJxTVa3OzMsssVKoVkrLyS9PzkgsKlEC8TJKcnN8EpNSc4qB3LTEnOLU2lqFWlVVLrgyBZ8gLgUgSEosTo3PzU9JzYlWStDSermo5cW6tc93N2tpgaWfTd3wrHfd+z2znm3d/rK9/9m09mdz1kAEwfJP9sx42jMNKA/U+Gxr95MdQNTwZMeqF+t7E5RiwUoy84pLikqTS5BseTqhD7stCk+XLAdZ09P+ZPcSbNYoBLuFPG5oDPJ5vrbz2bSdzzZPhVmTk1hcEl9QlJ9elJgbrQR0yLMdO57umvJ8ygqoAoRPbW3BHDBbwdbWDs2JWFwNVAURKE4uUYCaYYdiJRcAMU6xMw=="}),t[1]||(t[1]=e('<h2 id="训练阶段对比" tabindex="-1"><a class="header-anchor" href="#训练阶段对比"><span>训练阶段对比</span></a></h2><table><thead><tr><th>对比方面</th><th>预训练 (Pre-training)</th><th>后训练 (Post-training)</th></tr></thead><tbody><tr><td>核心目标</td><td>建立模型基础能力</td><td>将基座模型适配到具体应用场景</td></tr><tr><td>数据资源</td><td>数万亿词元的自然语言文本</td><td>数十万、数百万到数千万指令数据</td></tr><tr><td>所需算力</td><td>耗费百卡、千卡甚至万卡算力数月时间 <em>（大致估计）</em></td><td>耗费数十卡、数百卡数天到数十天时间 <em>（大致估计）</em></td></tr><tr><td>使用方式</td><td>通常为few-shot提示</td><td>可以直接进行zero-shot使用</td></tr></tbody></table><p><em>此部分算力估计为一个大致估计，需要根据模型大小、数据数量、训练框架等多方面因素确定</em></p><h2 id="大语言模型构建概览" tabindex="-1"><a class="header-anchor" href="#大语言模型构建概览"><span>大语言模型构建概览</span></a></h2><p>大语言模型预训练（Pre-training)</p><ul><li>使用与下游任务无关的大规模数据进行模型参数的初始训练 <ul><li>基于Transformer解码器架构，进行下一个词预测</li><li>数据数量、数据质量都比较关键</li></ul></li></ul><p>大语言模型后训练（Post-training)</p><ul><li>指令微调（Instruction Tuning)v 【有人也叫SFT】 <ul><li>使用输入与输出配对的指令数据对于模型进行微调</li><li>提升模型通过问答形式进行任务求解的能力</li></ul></li></ul><p><img src="'+s+'" alt="image-20250602105341874"></p><ul><li>人类对齐（Human Alignment） <ul><li>将大语言模型与人类的期望、需求以及价值对齐。</li><li>基于人类反馈的强化学习对齐（RLHF）。</li></ul></li></ul><p><img src="'+d+'" alt="image-20250602210703011"></p>',11))])}const u=r(m,[["render",p]]),h=JSON.parse('{"path":"/note-book/AI-Training/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80.html","title":"大模型技术基础","lang":"zh-CN","frontmatter":{"description":"大模型技术基础 大语言模型概念 定义： 通常指具有超大规模参数的预训练模型 架构：主要为transformer解码器架构 训练： 预训练（base model) 建立模型的基础能力 数据： 海量文本数据 优化：预测下一个词 后训练 (instruct model) 增强模型的任务能力 数据： 大量指令数据 优化： SFT、RL等方法 下游应用 测速（推...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"大模型技术基础\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-06-05T07:15:14.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Paper-Dragon\\",\\"url\\":\\"https://github.com/Paper-Dragon\\",\\"email\\":\\"2678885646@qq.com\\"}]}"],["meta",{"property":"og:url","content":"https://www.geekery.cn/note-book/AI-Training/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80.html"}],["meta",{"property":"og:site_name","content":"运维开发绿皮书"}],["meta",{"property":"og:title","content":"大模型技术基础"}],["meta",{"property":"og:description","content":"大模型技术基础 大语言模型概念 定义： 通常指具有超大规模参数的预训练模型 架构：主要为transformer解码器架构 训练： 预训练（base model) 建立模型的基础能力 数据： 海量文本数据 优化：预测下一个词 后训练 (instruct model) 增强模型的任务能力 数据： 大量指令数据 优化： SFT、RL等方法 下游应用 测速（推..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-06-05T07:15:14.000Z"}],["meta",{"property":"article:modified_time","content":"2025-06-05T07:15:14.000Z"}]]},"git":{"createdTime":1749107714000,"updatedTime":1749107714000,"contributors":[{"name":"Paper-Dragon","username":"Paper-Dragon","email":"2678885646@qq.com","commits":1,"url":"https://github.com/Paper-Dragon"}],"changelog":[{"hash":"bb8a1e70db02e492932b7b6fa6bc7e5ab0190842","time":1749107714000,"email":"2678885646@qq.com","author":"Paper-Dragon","message":"src/note-book/AI-Training/大语言模型基础.md"}]},"readingTime":{"minutes":1.84,"words":551},"filePathRelative":"note-book/AI-Training/大语言模型基础.md","excerpt":"\\n<h2>大语言模型概念</h2>\\n<p>定义： 通常指具有超大规模参数的预训练模型</p>\\n<p>架构：主要为transformer解码器架构</p>\\n<p>训练：</p>\\n<ul>\\n<li>预训练（base model)  建立模型的<strong>基础能力</strong>\\n<ul>\\n<li>数据： 海量文本数据</li>\\n<li>优化：预测下一个词</li>\\n</ul>\\n</li>\\n<li>后训练 (instruct model) 增强模型的<strong>任务能力</strong>\\n<ul>\\n<li>数据： 大量指令数据</li>\\n<li>优化： SFT、RL等方法</li>\\n</ul>\\n</li>\\n<li>下游应用\\n<ul>\\n<li>测速（推理）</li>\\n</ul>\\n</li>\\n</ul>","autoDesc":true}');export{u as comp,h as data};
