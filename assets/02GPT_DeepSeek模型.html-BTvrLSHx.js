import{a as t,c as a,g as p,o as s}from"./app-BrldQKfq.js";const i="/assets/image-20250612180148965-DsngjP18.png",n="/assets/image-20250612180511141-C1QGRfCX.png",r="/assets/image-20250612180746161-DFBkKcfS.png",d="/assets/image-20250612180922266-BLh2Qcoi.png",l="/assets/image-20250612181122284-B2wq_SYw.png",o="/assets/image-20250612181042124-C9FUj8cI.png",h="/assets/image-20250612181203851-B4YzJxM0.png",c="/assets/image-20250612181248831-CD_hBo2G.png",g="/assets/image-20250612181425607-Dj8N5E72.png",m="/assets/image-20250612181701766-BKxQUY6y.png",P="/assets/image-20250612181841882-DZ4U_CFr.png",T="/assets/image-20250612181919030-BPdigJYH.png",G="/assets/image-20250612182001336-DHrUHqc6.png",u="/assets/image-20250612182146103-BDW5K1N3.png",_="/assets/image-20250612183128860-GTEorE2w.png",k="/assets/image-20250612183250006-DW6FSmvA.png",b="/assets/image-20250612183458702-U64Qwsh7.png",f={};function D(x,e){return s(),a("div",null,[...e[0]||(e[0]=[p('<h1 id="gpt-deepseek模型" tabindex="-1"><a class="header-anchor" href="#gpt-deepseek模型"><span>GPT&amp;DeepSeek模型</span></a></h1><h2 id="gpt系列模型成体系推进" tabindex="-1"><a class="header-anchor" href="#gpt系列模型成体系推进"><span>GPT系列模型成体系推进</span></a></h2><table><thead><tr><th>年份</th><th>事件</th></tr></thead><tbody><tr><td>2017年</td><td>谷歌提出Transformer</td></tr><tr><td>2018年</td><td>OpenAI提出GPT（1亿+参数）</td></tr><tr><td>2019年</td><td>GPT - 2（15亿参数）</td></tr><tr><td>2020年</td><td>GPT - 3（1750亿参数）</td></tr><tr><td>2021年</td><td>CodeX（基于GPT - 3，代码预训练）</td></tr><tr><td>2021年</td><td>WebGPT（搜索能力）</td></tr><tr><td>2022年2月</td><td>InstructGPT（人类对齐）</td></tr><tr><td>2022年11月</td><td>ChatGPT（对话能力）</td></tr><tr><td>2023年3月</td><td>GPT - 4（推理能力、多模态能力）</td></tr><tr><td>2024年9月</td><td>o1（深度思考能力提升）</td></tr><tr><td>2025年1月</td><td>o3（深度思考能力进一步增强）</td></tr></tbody></table><ul><li>研究视野</li><li>技术人员</li><li>基础设施</li><li>工程实践</li><li>数据积累</li><li>算法设计</li></ul><p>GPT系列模型从18年开始系统迭代，对于大模型发展起到了深远影响</p><h2 id="gpt系列模型的技术演变" tabindex="-1"><a class="header-anchor" href="#gpt系列模型的技术演变"><span>GPT系列模型的技术演变</span></a></h2><p>GPT系列模型发展历程</p><ul><li><p>小模型：GPT-1、GPT-2</p></li><li><p>大模型：GPT-3、CodeX、GPT-3.5、GPT-4</p></li><li><p>推理大模型：o-series</p></li></ul><p><img src="'+i+'" alt="image-20250612180148965"></p><h3 id="gpt-1-1-1亿参数" tabindex="-1"><a class="header-anchor" href="#gpt-1-1-1亿参数"><span>GPT-1（1.1亿参数）</span></a></h3><ul><li>Decode-Only Transformer架构</li><li>预训练后针对特定任务微调</li></ul><p><img src="'+n+'" alt="image-20250612180511141"></p><h3 id="gpt-2-15亿参数" tabindex="-1"><a class="header-anchor" href="#gpt-2-15亿参数"><span>GPT-2(15亿参数)</span></a></h3><p>将任务形式统一为单词预测</p><ul><li>Pr( ouput |input, task)</li></ul><p>预训练与下游任务一致</p><p>使用提示进行无监督任务求解</p><p>初步尝试了规模扩展</p><p><img src="'+r+'" alt="image-20250612180746161"></p><h3 id="gpt-3-1750亿参数" tabindex="-1"><a class="header-anchor" href="#gpt-3-1750亿参数"><span>GPT-3(1750亿参数)</span></a></h3><p>涌现出上下文学习能力</p><p><img src="'+d+'" alt="image-20250612180922266"></p><h3 id="codex" tabindex="-1"><a class="header-anchor" href="#codex"><span>CodeX</span></a></h3><ul><li>代码数据训练</li><li>推理与代码合成能力</li></ul><p><strong>类似多模态</strong></p><p><img src="'+l+'" alt="image-20250612181122284"></p><p><img src="'+o+'" alt="image-20250612181042124"></p><h3 id="webgpt" tabindex="-1"><a class="header-anchor" href="#webgpt"><span>WebGPT</span></a></h3><p>大语言模型使用浏览器</p><p><img src="'+h+'" alt="image-20250612181203851"></p><h3 id="instructgpt" tabindex="-1"><a class="header-anchor" href="#instructgpt"><span>InstructGPT</span></a></h3><ul><li>大预言模型与人类价值观对其</li><li>提出RLHF算法</li></ul><p><img src="'+c+'" alt="image-20250612181248831"></p><h3 id="chatgpt" tabindex="-1"><a class="header-anchor" href="#chatgpt"><span>ChatGPT</span></a></h3><ul><li>基于InstructGPT相似技术开发，面向对话进行优化</li></ul><p><img src="'+g+'" alt="image-20250612181425607"></p><h3 id="gpt-4" tabindex="-1"><a class="header-anchor" href="#gpt-4"><span>GPT-4</span></a></h3><ul><li>推理能力显著提升，建立可预测的训练框架</li><li>可支持多模态信息的大语言模型</li></ul><p><img src="'+m+'" alt="image-20250612181701766">、、</p><h3 id="gpt-4o" tabindex="-1"><a class="header-anchor" href="#gpt-4o"><span>GPT-4o</span></a></h3><ul><li>原生多模态模型，综合模态能力显著提升</li><li>支持统一处理和输出文本、音频、图片、视频信息</li></ul><p><img src="'+P+'" alt="image-20250612181841882"></p><h3 id="o系列模型" tabindex="-1"><a class="header-anchor" href="#o系列模型"><span>o系列模型</span></a></h3><ul><li>推理任务上能力大幅提升</li><li>长思维链推理能力</li></ul><p><img src="'+T+'" alt="image-20250612181919030"></p><ul><li>类似人类“慢思考”过程</li></ul><p><img src="'+G+'" alt="image-20250612182001336"></p><h2 id="deepseek系列模型的技术演变" tabindex="-1"><a class="header-anchor" href="#deepseek系列模型的技术演变"><span>DeepSeek系列模型的技术演变</span></a></h2><p>训练框架： HAI-LLM</p><p>语言大模型： DeepSeek LLM/V2/V3、Coder/Coder-V2、Math</p><p>多模态大模型：DeepSeek-VL</p><p>推理大模型：DeepSeek-R1</p><p><img src="'+u+'" alt="image-20250612182146103"></p><h3 id="deepseek实现了较好的训练框架与数据准备" tabindex="-1"><a class="header-anchor" href="#deepseek实现了较好的训练框架与数据准备"><span>DeepSeek实现了较好的训练框架与数据准备</span></a></h3><p>训练框架 HAI-LLM（发布于2023年6月）</p><ul><li>大规模深度学习训练框架，支持多种并行策略</li><li>三代主力模型均基于该框架完成</li></ul><p>数据采集</p><ul><li>V1和Math的报告表明清洗了大规模的Common Crawl，具备超大规模数据处理能力</li><li>Coder的技术报告表明收集了大量的代码数据</li><li>Math的技术报告表明清洗收集了大量的数学数据</li><li>VL的技术报告表明清洗收集了大量多模态、图片数据</li></ul><h3 id="deepseek进行了重要的网络架构、训练算法、性能优化探索" tabindex="-1"><a class="header-anchor" href="#deepseek进行了重要的网络架构、训练算法、性能优化探索"><span>DeepSeek进行了重要的网络架构、训练算法、性能优化探索</span></a></h3><ul><li>V1探索了scalinglaw分析（考虑了数据质量影响），用于预估超参数性能</li><li>V2提出了MLA高效注意力机制，提升推理性能</li><li>V2、V3都针对MoE架构提出了相关稳定性训练策略</li><li>V3使用了MTP（多token预测）训练</li><li>Math提出了PPO的改进算法GRPO</li><li>V3详细介绍Infrastructure的搭建方法，并提出了高效FP8训练方法</li></ul><h3 id="deepseek-v3" tabindex="-1"><a class="header-anchor" href="#deepseek-v3"><span>DeepSeek-V3</span></a></h3><ul><li>671B参数（37B激活），14.8T训练数据</li><li>基于V2的MoE架构，引入了MTP和新的复杂均衡损失</li><li>对于训练效率进行了极致优化，共使用2.788MH800GPU时</li></ul><p><img src="'+_+'" alt="image-20250612183128860"></p><h3 id="deepseek-r1" tabindex="-1"><a class="header-anchor" href="#deepseek-r1"><span>DeepSeek-R1</span></a></h3><p><img src="'+k+'" alt="image-20250612183250006"></p><h3 id="deepseek-v3和deepseek-r1均达到了同期闭源模型的最好效果" tabindex="-1"><a class="header-anchor" href="#deepseek-v3和deepseek-r1均达到了同期闭源模型的最好效果"><span>DeepSeek-V3和DeepSeek-R1均达到了同期闭源模型的最好效果</span></a></h3><p><img src="'+b+'" alt="image-20250612183458702"></p><h3 id="为什么deepseek会引起世界关注" tabindex="-1"><a class="header-anchor" href="#为什么deepseek会引起世界关注"><span>为什么DeepSeek会引起世界关注</span></a></h3><ul><li><p>打破了OpenAI闭源产品的领先时效性</p></li><li><p>国内追赶GPT-4的时间很长，然而复现o1模型的时间大大缩短</p></li><li><p>达到了与OpenAI现有API性能可比的水平</p></li><li><p>中国具备实现世界最前沿大模型的核心技术</p></li><li><p>模型开源、技术开放</p></li></ul>',69)])])}const C=t(f,[["render",D]]),y=JSON.parse('{"path":"/note-book/AI-Training/02GPT_DeepSeek%E6%A8%A1%E5%9E%8B.html","title":"GPT&DeepSeek模型","lang":"zh-CN","frontmatter":{"description":"GPT&DeepSeek模型 GPT系列模型成体系推进 研究视野 技术人员 基础设施 工程实践 数据积累 算法设计 GPT系列模型从18年开始系统迭代，对于大模型发展起到了深远影响 GPT系列模型的技术演变 GPT系列模型发展历程 小模型：GPT-1、GPT-2 大模型：GPT-3、CodeX、GPT-3.5、GPT-4 推理大模型：o-series ...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"GPT&DeepSeek模型\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-06-18T01:52:45.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Paper-Dragon\\",\\"url\\":\\"https://github.com/Paper-Dragon\\",\\"email\\":\\"2678885646@qq.com\\"}]}"],["meta",{"property":"og:url","content":"https://www.geekery.cn/note-book/AI-Training/02GPT_DeepSeek%E6%A8%A1%E5%9E%8B.html"}],["meta",{"property":"og:site_name","content":"运维开发绿皮书"}],["meta",{"property":"og:title","content":"GPT&DeepSeek模型"}],["meta",{"property":"og:description","content":"GPT&DeepSeek模型 GPT系列模型成体系推进 研究视野 技术人员 基础设施 工程实践 数据积累 算法设计 GPT系列模型从18年开始系统迭代，对于大模型发展起到了深远影响 GPT系列模型的技术演变 GPT系列模型发展历程 小模型：GPT-1、GPT-2 大模型：GPT-3、CodeX、GPT-3.5、GPT-4 推理大模型：o-series ..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-06-18T01:52:45.000Z"}],["meta",{"property":"article:modified_time","content":"2025-06-18T01:52:45.000Z"}]]},"git":{"createdTime":1749428457000,"updatedTime":1750211565000,"contributors":[{"name":"Paper-Dragon","username":"Paper-Dragon","email":"2678885646@qq.com","commits":3,"url":"https://github.com/Paper-Dragon"}],"changelog":[{"hash":"4ec93fe31108bcd91455fde51905a2d7d33b611f","time":1750211565000,"email":"2678885646@qq.com","author":"Paper-Dragon","message":"排序 大语言模型"},{"hash":"060e0567ae7ab5f1ca993ab619a7d57bb5605a87","time":1749724684000,"email":"2678885646@qq.com","author":"Paper-Dragon","message":"GPT系列模型的技术演变，DeepSeek系列模型的技术演变"},{"hash":"f4197279192ec41473e232ea2e7736b1fa2ef867","time":1749428457000,"email":"2678885646@qq.com","author":"Paper-Dragon","message":"GPT&#x26;DeepSeek模型.md"}]},"readingTime":{"minutes":3.73,"words":1119},"filePathRelative":"note-book/AI-Training/02GPT&DeepSeek模型.md","excerpt":"\\n<h2>GPT系列模型成体系推进</h2>\\n<table>\\n<thead>\\n<tr>\\n<th>年份</th>\\n<th>事件</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td>2017年</td>\\n<td>谷歌提出Transformer</td>\\n</tr>\\n<tr>\\n<td>2018年</td>\\n<td>OpenAI提出GPT（1亿+参数）</td>\\n</tr>\\n<tr>\\n<td>2019年</td>\\n<td>GPT - 2（15亿参数）</td>\\n</tr>\\n<tr>\\n<td>2020年</td>\\n<td>GPT - 3（1750亿参数）</td>\\n</tr>\\n<tr>\\n<td>2021年</td>\\n<td>CodeX（基于GPT - 3，代码预训练）</td>\\n</tr>\\n<tr>\\n<td>2021年</td>\\n<td>WebGPT（搜索能力）</td>\\n</tr>\\n<tr>\\n<td>2022年2月</td>\\n<td>InstructGPT（人类对齐）</td>\\n</tr>\\n<tr>\\n<td>2022年11月</td>\\n<td>ChatGPT（对话能力）</td>\\n</tr>\\n<tr>\\n<td>2023年3月</td>\\n<td>GPT - 4（推理能力、多模态能力）</td>\\n</tr>\\n<tr>\\n<td>2024年9月</td>\\n<td>o1（深度思考能力提升）</td>\\n</tr>\\n<tr>\\n<td>2025年1月</td>\\n<td>o3（深度思考能力进一步增强）</td>\\n</tr>\\n</tbody>\\n</table>","autoDesc":true}');export{C as comp,y as data};
